{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bridgingo Sentiment Analysis .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPuzk4fGROSBqjz1ZKDztdr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shyam1234/AIML_RND/blob/master/Bridgingo_Sentiment_Analysis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuJRkwuSdklx",
        "colab_type": "text"
      },
      "source": [
        "# **Bridgingo Sentiment Analysis**  \n",
        "This is for demonstrating the Sentiment analysis based on the live twitter feed.\n",
        "###### Auther : Prafulla Malviya (AIML Enthusiastic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hGbUjL7dwel",
        "colab_type": "text"
      },
      "source": [
        "##**Agenda**\n",
        "\n",
        "\n",
        "1.   NLP (Natural Language Processing)\n",
        "2.   Sentiment Analysis\n",
        "3.   Connect Twitter with Collab\n",
        "4.   Tweets Preprocessing and Cleaning\n",
        "5.   Visualization from Tweets \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZA7MziOkfEK",
        "colab_type": "text"
      },
      "source": [
        "###1. **Natural Language Processing**\n",
        "Simple Defination: NLP is a field in machine learning with the ability of a computer to understand, analyze, manipulate, and potentially generate human language.\n",
        "\n",
        "####**NLP in Real Life** \n",
        "\n",
        "\n",
        "*   Information Retrieval(Google finds relevant and similar results).\n",
        "* Information Extraction(Gmail structures events from emails).\n",
        "* Machine Translation(Google Translate translates language from one language to another).\n",
        "* Text Simplification(Rewordify simplifies the meaning of sentences). Shashi * * Tharoor tweets could be used(pun intended).\n",
        "* Sentiment Analysis(Hater News gives us the sentiment of the user).\n",
        "* Text Summarization(Smmry or Reddit’s autotldr gives a summary of sentences).\n",
        "* Spam Filter(Gmail filters spam emails separately).\n",
        "* Auto-Predict(Google Search predicts user search results).\n",
        "* Auto-Correct(Google Keyboard and Grammarly correct words otherwise spelled wrong).\n",
        "* Speech Recognition(Google WebSpeech or Vocalware).\n",
        "* Question Answering(IBM Watson’s answers to a query).\n",
        "* Natural Language Generation(Generation of text from image or video data.)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRXfHA4Klk2_",
        "colab_type": "text"
      },
      "source": [
        "(Natural Language Toolkit)NLTK: NLTK is a popular open-source package in Python. Rather than building all tools from scratch, NLTK provides all common NLP Tasks.\n",
        "\n",
        "\n",
        "Concept of Tokenization, Stemming, and Lemmatization \n",
        "\n",
        "\n",
        "**Stemming**\n",
        "While working with words, we come across a lot of variations due to grammatical reasons. The concept of variations here means that we have to deal with different forms of the same words like democracy, democratic, and democratization. It is very necessary for machines to understand that these different words have the same base form. In this way, it would be useful to extract the base forms of the words while we are analyzing the text.\n",
        "\n",
        "**Lemmatization**\n",
        "\n",
        "We can also extract the base form of words by lemmatization. It basically does this task with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only. This kind of base form of any word is called lemma.\n",
        "\n",
        "**('walk', 'walked', 'walks', 'walking)**\n",
        "\n",
        "\n",
        "**Model:**\n",
        "\n",
        "Beg of words, TF-IDF and N-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFhUPXYWd6i0",
        "colab_type": "text"
      },
      "source": [
        "###2. **Sentiment Analysis** \n",
        "the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer’s attitude towards a particular topic, product, etc. is positive, negative, or neutral. **-Oxford dictionary**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0-EgmKjeQWq",
        "colab_type": "text"
      },
      "source": [
        "There are many methods and algorithms to implement sentiment analysis systems, which can be classified as:\n",
        "\n",
        "\n",
        "*   **Rule-based** systems that perform sentiment analysis based on a set of manually crafted rules.\n",
        "*   **Automatic systems** that rely on machine learning techniques to learn from data.\n",
        "*   **Hybrid systems** that combine both rule based and automatic approaches.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IOttatkrVcF",
        "colab_type": "text"
      },
      "source": [
        "There are mainly two approaches for performing sentiment analysis (Defined by University of Victoria)\n",
        "\n",
        "1.   **Lexicon based**: count number of positive and negative words in given text and the larger count will be the sentiment of text\n",
        "2.   **Machine learning based approach**: Develop a classification model, which is trained using the pre-labeled dataset of positive, negative, and neutral\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FNBxC2qe3PE",
        "colab_type": "text"
      },
      "source": [
        "### Create the Twitter application for getting live tweet "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hOYfZrpfPa1",
        "colab_type": "text"
      },
      "source": [
        "A. Go to \"https://developer.twitter.com\" for creating the Twitter application \n",
        "B. Then go to \"Keys and tokens\" and then copy the **API key**, **Access token, Access token secret** and **API secret key**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4dwcYTxhhDm",
        "colab_type": "text"
      },
      "source": [
        "### Lets code now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYFjA9VpmaB9",
        "colab_type": "text"
      },
      "source": [
        "###3.**Connect Twitter with Collab** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Eim5VO53iJz",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "49c5cd48-d229-43fb-fda5-6f97e640ca2d"
      },
      "source": [
        "#Load the twitter application credential\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6286ceda-60d2-431f-8fb8-b2a9e57a62c7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6286ceda-60d2-431f-8fb8-b2a9e57a62c7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving login.csv to login (2).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62r4SPIc3poD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the data\n",
        "log = pd.read_csv('login.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIDKN7D23uaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "bae8b01e-8804-4662-9bd1-f178587171f9"
      },
      "source": [
        "log"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Key</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>API key</td>\n",
              "      <td>fHV3qYN89cP7Ey1x5uYKfpcts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>API secret key</td>\n",
              "      <td>IPRozWHZUncAgu6QBb7uXZgclhGt3wi6BNO6O9NlgUTHYX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Access token</td>\n",
              "      <td>302080916-EA9dBK8rn7OIKfZriQ7rhb4iiKWBz9sjcrTS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Access token secret</td>\n",
              "      <td>1lnjgSPdEHJBn7cMDz6mq4XmZTYJiy4YDsPlmwqHAAbyq</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Key                                              value\n",
              "0              API key                          fHV3qYN89cP7Ey1x5uYKfpcts\n",
              "1       API secret key  IPRozWHZUncAgu6QBb7uXZgclhGt3wi6BNO6O9NlgUTHYX...\n",
              "2         Access token  302080916-EA9dBK8rn7OIKfZriQ7rhb4iiKWBz9sjcrTS...\n",
              "3  Access token secret      1lnjgSPdEHJBn7cMDz6mq4XmZTYJiy4YDsPlmwqHAAbyq"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCEyKM5Ekr-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Twitter API credentials\n",
        "consumerKey = log['value'][0]\n",
        "consumerSecret = log['value'][1]\n",
        "accessToken = log['value'][2]\n",
        "accessTokenSecret = log['value'][3] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEuImkK93xoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import the libraries \n",
        "import tweepy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvbnKL0j35eC",
        "colab_type": "text"
      },
      "source": [
        "#### **What is tweepy?**\n",
        "An easy-to-use Python library for accessing the Twitter API. It is great for simple automation and creating twitter bots. \n",
        "\n",
        "[Documentation](http://docs.tweepy.org/en/v3.5.0/index.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RprNiXiilKAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the authentication object. Into this we pass our consumer token and secret \n",
        "authenticate =  tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
        "\n",
        "# Set the access token and access token secret\n",
        "authenticate.set_access_token(accessToken, accessTokenSecret)\n",
        "\n",
        "# Create the API object while passing in the auth information (Twitter API wrapper)\n",
        "api = tweepy.API(authenticate, wait_on_rate_limit= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbKY2gVRoyYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "authenticate.access_token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbLlw2iBnGLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract 100 tweets from the twitter user (getting time line tweet : user_timeline)\n",
        "posts = api.user_timeline(screen_name=\"MadhuriDixit\", count = 100, lang= \"en\", tweet_mode= \"extended\")\n",
        "\n",
        "# Print the last five tweets from the account\n",
        "print(\"/* Show the last five recent tweets */ \\n\")\n",
        "i = 1\n",
        "for tweet in posts[0:5]:\n",
        "  print(str(i)+')'+tweet.full_text +'\\n')\n",
        "  i = i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM-NFAHN6D5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkAMx6-y53fk",
        "colab_type": "text"
      },
      "source": [
        "#### **What is Pandas?**\n",
        "Pandas is one of the most widely used python libraries in data science. It provides high-performance, easy to use structures and data analysis tools. Pandas uses for Dataframe to manipulate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWIhY2aXqChU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the dataframe with a column called Tweets\n",
        "df =  pd.DataFrame([tweet.full_text for tweet in posts], columns=['Tweets'])\n",
        "\n",
        "# Show the first 5 rows of data\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HASzbRCfmxww",
        "colab_type": "text"
      },
      "source": [
        "###4. **Tweets Preprocessing and Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAlPorpp6IBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vbbi63Tqpel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean the tweets. Try to remove the unwanted things from the tweets\n",
        "# Create the function to clean the tweets\n",
        "def cleanTxt(text):\n",
        "  text = re.sub(r'@[A-Za-z0-9]+', '', text) # Removed @mentions\n",
        "  text = re.sub(r'#','',text) #Removed the '#'\n",
        "  text = re.sub(r'#','',text) #Removed the '#'\n",
        "  text = re.sub(r'RT[\\s]+','',text) # Removed RT\n",
        "  #text = re.sub(r'https?:\\/\\/\\/S+','',text) #Remove the hyperlink\n",
        "  text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) #Remove the hyperlink\n",
        "  text = re.sub(r'^http?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) #Remove the hyperlink\n",
        "  text = re.sub(r'&amp','',text)\n",
        "  text = re.sub(r\"http\\S+\", \"\", text)\n",
        "\n",
        "  return text\n",
        "\n",
        "#Clean the text\n",
        "df['Tweets'] = df['Tweets'].apply(cleanTxt)\n",
        "#Show the cleaned text\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSSQKLZH6LJi",
        "colab_type": "text"
      },
      "source": [
        "#### **What is Polarity?**\n",
        "It defines the **emotions** expressed in a sentence between **-1 to 1**. \n",
        "\n",
        "1.   negative value shows negative emotion\n",
        "2.   0 value shows neutral \n",
        "3.   positive value shows positive emotion\n",
        "\n",
        "Example\n",
        "1.   I want to thank our Indians to support us to fight against coronavirus virus.  (Positive)\n",
        "2.   We should fight with enemies. (Negative)\n",
        "3.   We think to support other country some other time. (Seems Neutral)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxgtPEyZ6VI8",
        "colab_type": "text"
      },
      "source": [
        "#### **What is Subjectivity?**\n",
        "It identifies **subjective** and **objective** sentence between **0 to 1**. \n",
        "\n",
        "Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information.\n",
        "\n",
        "Example\n",
        "1.   THANK YOU TEXAS  (Subjective)\n",
        "2.   I am pleased to announce that Congressman Mark will become White House Chief of Staff (Objective)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ65OpSqYPqw",
        "colab_type": "text"
      },
      "source": [
        "The sentiment function of textblob returns two properties, **polarity**, and **subjectivity**.\n",
        "\n",
        "**Polarity** is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement. \n",
        "\n",
        "**Subjective** sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information. Subjectivity is also a float which lies in the range of [0,1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOP57-Oa6inv",
        "colab_type": "text"
      },
      "source": [
        "##### **What is TextBlob?**\n",
        "TextBlob is a python library and offers a simple API to access its methods and perform basic NLP tasks. It is  for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgp337mD8KYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD_VxVMislm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the function to get the subjectivity\n",
        "def getSubjectivity(text):\n",
        "  return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "# Create the function to get the polarity\n",
        "def getPolarity(text):\n",
        "  return TextBlob(text).sentiment.polarity\n",
        "\n",
        "# Create two new columns\n",
        "df['Subjectivity'] = df['Tweets'].apply(getSubjectivity)\n",
        "df['Polarity'] = df['Tweets'].apply(getPolarity)\n",
        "\n",
        "#Show the new dataframe with new added column\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlLm8nja6rU8",
        "colab_type": "text"
      },
      "source": [
        "#### **What is WordCloud?**\n",
        "Word Cloud is a data visualization technique used for representing text data in which the size of each word indicates its frequency or importance. Significant textual data points can be highlighted using a word cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHxR9O-4658Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3d55HQj8s6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot Word Cloud\n",
        "allWords =  ' '.join([twts for twts in df['Tweets']])\n",
        "wordCloud = WordCloud( width = 500, height  =300 , random_state = 21, max_font_size = 119).generate(allWords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyl0PZ9j7LE3",
        "colab_type": "text"
      },
      "source": [
        "#### **What is Matplotlib?**\n",
        "In short: Matplotlib is used for visualizing the data.\n",
        "\n",
        "Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYeH1sMS8p2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gNduxmVtoH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(wordCloud, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeohSG5lveUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the function to compute the negative, neutral and positive analysis\n",
        "def getAnalysis(score):\n",
        "  if score < 0:\n",
        "    return 'Negative'\n",
        "  elif score == 0:\n",
        "    return 'Neutral'\n",
        "  else:\n",
        "    return 'Positive'\n",
        "  \n",
        "df['Analysis'] = df['Polarity'].apply(getAnalysis)\n",
        "\n",
        "#Show the dataframe\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1gVOOi5w6_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print all the positive tweets\n",
        "j = 1\n",
        "sortedDf =  df.sort_values(by=['Polarity'])\n",
        "for i  in range(0, sortedDf.shape[0]):\n",
        "  if (sortedDf['Analysis'][i] == 'Positive'):\n",
        "    print(str(j) + ')'+sortedDf['Tweets'][i])\n",
        "    print()\n",
        "    j = j+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzdHLq_syLES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets print the negative tweets\n",
        "j = 1\n",
        "sortedDf = df.sort_values(by=['Polarity'], ascending=False)\n",
        "for i in range(0, sortedDf.shape[0]):\n",
        "  if(sortedDf['Analysis'][i] == 'Negative'):\n",
        "    print(str(j) +')'+sortedDf['Tweets'][i])\n",
        "    print()\n",
        "    j = j+1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x5PYb6-nDpV",
        "colab_type": "text"
      },
      "source": [
        "###5. **Visualization from Tweets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iijKadXGzTe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the polarity and subjectivity\n",
        "plt.figure(figsize=(8,6))\n",
        "for i in range(0, df.shape[0]):\n",
        "  plt.scatter(df['Polarity'][i], df['Subjectivity'][i], color= 'Blue')\n",
        "\n",
        "plt.title('Sentiment Analysis')\n",
        "plt.xlabel('Polarity')\n",
        "plt.ylabel('Subjectivity')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAu11EYb0WXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the percentage of positive tweets\n",
        "ptweets = df[df.Analysis == 'Positive']\n",
        "ptweets = ptweets['Tweets']\n",
        "\n",
        "round((ptweets.shape[0]/df.shape[0])*100,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AF8WFQM1BpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the percentage of negative tweets\n",
        "ntweets = df[df.Analysis == 'Negative']\n",
        "ntweets = ntweets['Tweets']\n",
        "\n",
        "round((ntweets.shape[0]/df.shape[0]*100),1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pmcskWE1avX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show the value counts\n",
        "\n",
        "df['Analysis'].value_counts()\n",
        "\n",
        "#plot and visualize the count\n",
        "plt.title('Sentiment Analysis')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "df['Analysis'].value_counts().plot(kind=\"bar\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69r18PKozmKu",
        "colab_type": "text"
      },
      "source": [
        "For ref:\n",
        "a. https://www.analyticsvidhya.com/blog/2018/02/natural-language-processing-for-beginners-using-textblob/"
      ]
    }
  ]
}