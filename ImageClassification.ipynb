{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLMCtZjRpyLm74zVbeeruf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shyam1234/AIML_RND/blob/master/ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_74o0j050Cj"
      },
      "source": [
        "#Image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcQEP5-f56aG"
      },
      "source": [
        "**Instruction**\n",
        "\n",
        "Image classification is an important task for computer vision application. Image classification\n",
        "algorithms made advancement from traditional feature-based methods to deep learning-based\n",
        "techniques. Deep learning, particularly the convolutional neural network, has been a success story in\n",
        "the last decade and significantly improved classification accuracy. In this task, you need to build a CNN\n",
        "architecture and optimise it for classification. Following tasks are to be carried out. You are\n",
        "encouraged to use Google Colab (https://colab.research.google.com/) with the GPU option enabled\n",
        "where suitable. Please use Keras deep learning framework for this part of the assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-sx3OYv6XSz"
      },
      "source": [
        "1. Load the CIFAR10 small images classification dataset from Keras inbuilt datasets(https://keras.io/api/datasets/cifar10/). Display 10 random images from each of the 10\n",
        "classes (the images should change in every run).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G16QEdIR66lf"
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrTf1oQigpEA"
      },
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from IPython.display import Image\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmhjDtTYEqqC"
      },
      "source": [
        "# load dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\treturn trainX, trainY, testX, testY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nH53X72nnES"
      },
      "source": [
        "# load dataset\n",
        "trainX, trainY, testX, testY = load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC8djcYJ8ut_"
      },
      "source": [
        "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRDgGLkSLRGn"
      },
      "source": [
        "import random\n",
        "\n",
        "randomlist = []\n",
        "uniqueIndex = []\n",
        "MAX_LIMIT = 5000\n",
        "\n",
        "index = 0\n",
        "while index < len(cifar10_classes):\n",
        "  num = random.randint(0,MAX_LIMIT)\n",
        "  label = [trainY[num][0]]\n",
        "  if label not in randomlist:\n",
        "    randomlist.append(label[0])\n",
        "    uniqueIndex.append(num)\n",
        "    index = index+1\n",
        "\n",
        "#print(randomlist)\n",
        "#print(uniqueIndex)\n",
        "\n",
        "# plot the images WRT uniqueIndex\n",
        "pyplot.figure(figsize=(10, 10))\n",
        "for i in range(10):\n",
        "  pyplot.subplot(5, 5, i + 1)\n",
        "  pyplot.imshow(trainX[uniqueIndex[i]])\n",
        "  pyplot.title(cifar10_classes[trainY[uniqueIndex[i]][0]])\n",
        "  pyplot.axis(\"off\")\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuwXmjvsgd9a"
      },
      "source": [
        "2. For the classification (10 image classes), write Python code to create a basic CNN network of \n",
        "your choice (can be anything from practical 7, LeNet, AlexNet etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq2yDfahoKa7"
      },
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfkLqL61qVlA"
      },
      "source": [
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNFxXqwxqh_u"
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history, epoch):\n",
        "  # plot loss\n",
        "  pyplot.subplot(211)\n",
        "  pyplot.title('Cross Entropy Loss')\n",
        "  pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "  pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "  # plot accuracy\n",
        "  pyplot.subplot(212)\n",
        "  pyplot.title('Classification Accuracy')\n",
        "  pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "  pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "  # save plot to file\n",
        "  filename = \"epoch_\"+epoch+ '_plot.png'\n",
        "  pyplot.savefig(filename)\n",
        "  pyplot.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ge_jlsfn_iA"
      },
      "source": [
        "# evaluating a model\n",
        "def trainModel(epochsValue):\n",
        "  # load dataset\n",
        "  trainX, trainY, testX, testY = load_dataset()\n",
        "  trainY = to_categorical(trainY)\n",
        "  testY = to_categorical(testY)\n",
        "\t# prepare pixel data\n",
        "  trainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "  model = define_model()\n",
        "\t# fit model\n",
        "  history = model.fit(trainX, trainY, epochs=epochsValue, batch_size=64, validation_data=(testX, testY), verbose=0)\n",
        "\t# evaluate model\n",
        "  _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "  test_loss, test_acc = model.evaluate(testX,  testY, verbose=2)\n",
        "  # learning curves\n",
        "  summarize_diagnostics(history,str(epochsValue))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_exwkwouuPHj"
      },
      "source": [
        "3. Train and test the network and report the training loss, training accuracy and test accuracy for \n",
        "various epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mULpdjT_oByN"
      },
      "source": [
        "trainModel(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXdy6yB36XxM"
      },
      "source": [
        "Image('/content/epoch_10_plot.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHPscPZD6g14"
      },
      "source": [
        "trainModel(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA79T-O76iMG"
      },
      "source": [
        "Image('/content/epoch_20_plot.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTC8S267RjE"
      },
      "source": [
        "4.Improve the architecture by changing the parameters, including but not limited to, learning \n",
        "rate, epochs, size of the convolution filters, use of average pooling or max-pooling etc. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kB4PlKG9t3Z"
      },
      "source": [
        "Added more MaxPool and Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CylbQyxM7Tzf"
      },
      "source": [
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj1CUayq9fQp"
      },
      "source": [
        "trainModel(10)\n",
        "# try with 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuzrRtie9iev"
      },
      "source": [
        "Image('/content/epoch_10_plot.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RFITtys-WsN"
      },
      "source": [
        "5.Improve the architecture by introducing more convolutional and corresponding subsampling \n",
        "layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEhfqG8y-Zk6"
      },
      "source": [
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4acA0PqO-qWv"
      },
      "source": [
        "trainModel(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqmHr63N-q60"
      },
      "source": [
        "Image('/content/epoch_50_plot.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tEYv7n5-sJt"
      },
      "source": [
        "6. Your final code should accept single image on the trained network and produce the output \n",
        "class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBIGOTy4-rRb"
      },
      "source": [
        "define_model().summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAfEyQeD_lrz"
      },
      "source": [
        "# save model\n",
        "model.save('final_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKBWxOUvF8g1"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qydiHH0tEJFV"
      },
      "source": [
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(32, 32))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 32, 32, 3)\n",
        "\t# prepare pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B0A8Dp0EWDm"
      },
      "source": [
        "def identifyImage(fileName):\n",
        "\t# load the image\n",
        "  img = load_image(fileName)\n",
        "  # load model\n",
        "  model = load_model('final_model.h5')\n",
        "  # predict the class\n",
        "  result = model.predict_classes(img)\n",
        "  Image(fileName)\n",
        "  print(cifar10_classes[result[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq0JbSJLHEJM"
      },
      "source": [
        "Image('/content/test_image.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ8w00sqFIPa"
      },
      "source": [
        "identifyImage('/content/test_image.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}